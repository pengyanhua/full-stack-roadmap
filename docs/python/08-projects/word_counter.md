# word counter.py

::: info æ–‡ä»¶ä¿¡æ¯
- ğŸ“„ åŸæ–‡ä»¶ï¼š`02_word_counter.py`
- ğŸ”¤ è¯­è¨€ï¼špython
:::

é¡¹ç›®2ï¼šæ–‡æœ¬åˆ†æå™¨ï¼ˆè¯é¢‘ç»Ÿè®¡ï¼‰
ä¸€ä¸ªæ–‡æœ¬åˆ†æå·¥å…·ï¼Œå¯ä»¥ç»Ÿè®¡è¯é¢‘ã€å­—ç¬¦æ•°ç­‰ä¿¡æ¯ã€‚

åŠŸèƒ½ï¼š
- ç»Ÿè®¡å•è¯é¢‘ç‡
- è®¡ç®—å­—ç¬¦æ•°ã€å•è¯æ•°ã€è¡Œæ•°
- æ‰¾å‡ºæœ€å¸¸è§çš„å•è¯
- æ”¯æŒæ–‡ä»¶è¾“å…¥å’Œå­—ç¬¦ä¸²è¾“å…¥

çŸ¥è¯†ç‚¹ï¼š
- æ–‡ä»¶æ“ä½œ
- å­—ç¬¦ä¸²å¤„ç†
- æ­£åˆ™è¡¨è¾¾å¼
- collections.Counter
- æ•°æ®åˆ†æ

## å®Œæ•´ä»£ç 

```python
import re
from collections import Counter
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass


@dataclass
class TextStats:
    """æ–‡æœ¬ç»Ÿè®¡ç»“æœ"""
    char_count: int
    char_count_no_spaces: int
    word_count: int
    line_count: int
    sentence_count: int
    avg_word_length: float
    avg_words_per_sentence: float


class TextAnalyzer:
    """æ–‡æœ¬åˆ†æå™¨"""

    def __init__(self, text: str = ""):
        self.text = text
        self._words: List[str] = []
        self._word_freq: Counter = Counter()

        if text:
            self._analyze()

    def load_file(self, filepath: str) -> None:
        """ä»æ–‡ä»¶åŠ è½½æ–‡æœ¬"""
        path = Path(filepath)
        if not path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")

        self.text = path.read_text(encoding='utf-8')
        self._analyze()

    def load_text(self, text: str) -> None:
        """åŠ è½½æ–‡æœ¬å­—ç¬¦ä¸²"""
        self.text = text
        self._analyze()

    def _analyze(self) -> None:
        """åˆ†ææ–‡æœ¬"""
        # æå–å•è¯ï¼ˆåªåŒ…å«å­—æ¯å’Œæ•°å­—ï¼‰
        self._words = re.findall(r'\b[a-zA-Z]+\b', self.text.lower())
        self._word_freq = Counter(self._words)

    def get_stats(self) -> TextStats:
        """è·å–æ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯"""
        lines = self.text.split('\n')
        sentences = re.split(r'[.!?]+', self.text)
        sentences = [s.strip() for s in sentences if s.strip()]

        total_word_length = sum(len(word) for word in self._words)
        avg_word_length = total_word_length / len(self._words) if self._words else 0

        return TextStats(
            char_count=len(self.text),
            char_count_no_spaces=len(self.text.replace(' ', '').replace('\n', '')),
            word_count=len(self._words),
            line_count=len(lines),
            sentence_count=len(sentences),
            avg_word_length=round(avg_word_length, 2),
            avg_words_per_sentence=round(len(self._words) / len(sentences), 2) if sentences else 0
        )

    def word_frequency(self) -> Counter:
        """è·å–è¯é¢‘ç»Ÿè®¡"""
        return self._word_freq

    def most_common(self, n: int = 10) -> List[Tuple[str, int]]:
        """è·å–æœ€å¸¸è§çš„ n ä¸ªå•è¯"""
        return self._word_freq.most_common(n)

    def search_word(self, word: str) -> Dict:
        """æœç´¢å•è¯å‡ºç°ä¿¡æ¯"""
        word = word.lower()
        count = self._word_freq.get(word, 0)

        # æ‰¾å‡ºæ‰€æœ‰å‡ºç°ä½ç½®
        positions = []
        for match in re.finditer(rf'\b{re.escape(word)}\b', self.text.lower()):
            positions.append(match.start())

        return {
            'word': word,
            'count': count,
            'positions': positions,
            'percentage': round(count / len(self._words) * 100, 2) if self._words else 0
        }

    def get_unique_words(self) -> List[str]:
        """è·å–æ‰€æœ‰ä¸é‡å¤çš„å•è¯"""
        return list(self._word_freq.keys())

    def get_word_length_distribution(self) -> Dict[int, int]:
        """è·å–å•è¯é•¿åº¦åˆ†å¸ƒ"""
        distribution = Counter(len(word) for word in self._words)
        return dict(sorted(distribution.items()))

    def find_words_by_length(self, length: int) -> List[str]:
        """æ‰¾å‡ºæŒ‡å®šé•¿åº¦çš„å•è¯"""
        return list(set(word for word in self._words if len(word) == length))

    def print_report(self) -> None:
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        stats = self.get_stats()
        most_common = self.most_common(10)
        length_dist = self.get_word_length_distribution()

        print("\n" + "=" * 50)
        print("           æ–‡æœ¬åˆ†ææŠ¥å‘Š")
        print("=" * 50)

        print("\nã€åŸºæœ¬ç»Ÿè®¡ã€‘")
        print(f"  å­—ç¬¦æ•°: {stats.char_count}")
        print(f"  å­—ç¬¦æ•°ï¼ˆä¸å«ç©ºæ ¼ï¼‰: {stats.char_count_no_spaces}")
        print(f"  å•è¯æ•°: {stats.word_count}")
        print(f"  è¡Œæ•°: {stats.line_count}")
        print(f"  å¥å­æ•°: {stats.sentence_count}")
        print(f"  å¹³å‡å•è¯é•¿åº¦: {stats.avg_word_length}")
        print(f"  å¹³å‡æ¯å¥å•è¯æ•°: {stats.avg_words_per_sentence}")

        print("\nã€æœ€å¸¸è§çš„ 10 ä¸ªå•è¯ã€‘")
        for i, (word, count) in enumerate(most_common, 1):
            percentage = count / stats.word_count * 100 if stats.word_count else 0
            bar = "â–ˆ" * int(percentage)
            print(f"  {i:2}. {word:15} {count:5} ({percentage:5.2f}%) {bar}")

        print("\nã€å•è¯é•¿åº¦åˆ†å¸ƒã€‘")
        max_count = max(length_dist.values()) if length_dist else 0
        for length, count in length_dist.items():
            bar_width = int(count / max_count * 20) if max_count else 0
            bar = "â–ˆ" * bar_width
            print(f"  {length:2} å­—æ¯: {count:5} {bar}")

        print("\nã€å…¶ä»–ç»Ÿè®¡ã€‘")
        print(f"  ä¸é‡å¤å•è¯æ•°: {len(self.get_unique_words())}")
        print(f"  è¯æ±‡ä¸°å¯Œåº¦: {len(self.get_unique_words()) / stats.word_count * 100:.2f}%"
              if stats.word_count else "  è¯æ±‡ä¸°å¯Œåº¦: 0%")

        print("=" * 50)


def demo():
    """æ¼”ç¤º"""
    sample_text = """
    Python is a programming language that lets you work quickly
    and integrate systems more effectively. Python is powerful and fast.
    Python plays well with others. Python runs everywhere.
    Python is friendly and easy to learn. Python is Open.

    The Python Software Foundation is an organization devoted to
    advancing open source technology related to the Python programming language.
    """

    print("ã€æ–‡æœ¬åˆ†æå™¨æ¼”ç¤ºã€‘\n")

    analyzer = TextAnalyzer(sample_text)
    analyzer.print_report()

    # æœç´¢ç‰¹å®šå•è¯
    print("\nã€æœç´¢å•è¯ 'python'ã€‘")
    result = analyzer.search_word('python')
    print(f"  å‡ºç°æ¬¡æ•°: {result['count']}")
    print(f"  å æ¯”: {result['percentage']}%")
    print(f"  ä½ç½®: {result['positions'][:5]}...")

    # æ‰¾å‡ºç‰¹å®šé•¿åº¦çš„å•è¯
    print("\nã€6 ä¸ªå­—æ¯çš„å•è¯ã€‘")
    words = analyzer.find_words_by_length(6)
    print(f"  {', '.join(words[:10])}")


def main():
    """ä¸»å‡½æ•° - äº¤äº’æ¨¡å¼"""
    print("=" * 50)
    print("      æ¬¢è¿ä½¿ç”¨ Python æ–‡æœ¬åˆ†æå™¨")
    print("=" * 50)
    print("""
å‘½ä»¤:
  load <file>    ä»æ–‡ä»¶åŠ è½½æ–‡æœ¬
  text           è¾“å…¥æ–‡æœ¬ï¼ˆå¤šè¡Œï¼Œç©ºè¡Œç»“æŸï¼‰
  stats          æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
  top <n>        æ˜¾ç¤ºæœ€å¸¸è§çš„ n ä¸ªå•è¯
  search <word>  æœç´¢å•è¯
  report         æ˜¾ç¤ºå®Œæ•´æŠ¥å‘Š
  demo           è¿è¡Œæ¼”ç¤º
  quit           é€€å‡º
""")

    analyzer = TextAnalyzer()

    while True:
        try:
            user_input = input(">>> ").strip()
            if not user_input:
                continue

            parts = user_input.split(maxsplit=1)
            command = parts[0].lower()
            args = parts[1] if len(parts) > 1 else ""

            if command == "quit" or command == "exit":
                print("å†è§ï¼")
                break

            elif command == "demo":
                demo()

            elif command == "load":
                if not args:
                    print("è¯·æä¾›æ–‡ä»¶è·¯å¾„")
                else:
                    try:
                        analyzer.load_file(args)
                        print(f"å·²åŠ è½½æ–‡ä»¶: {args}")
                    except FileNotFoundError as e:
                        print(e)

            elif command == "text":
                print("è¾“å…¥æ–‡æœ¬ï¼ˆç©ºè¡Œç»“æŸï¼‰:")
                lines = []
                while True:
                    line = input()
                    if not line:
                        break
                    lines.append(line)
                analyzer.load_text('\n'.join(lines))
                print("æ–‡æœ¬å·²åŠ è½½")

            elif command == "stats":
                if not analyzer.text:
                    print("è¯·å…ˆåŠ è½½æ–‡æœ¬")
                else:
                    stats = analyzer.get_stats()
                    print(f"\nå•è¯æ•°: {stats.word_count}")
                    print(f"å­—ç¬¦æ•°: {stats.char_count}")
                    print(f"è¡Œæ•°: {stats.line_count}")

            elif command == "top":
                n = int(args) if args else 10
                top_words = analyzer.most_common(n)
                print(f"\næœ€å¸¸è§çš„ {n} ä¸ªå•è¯:")
                for word, count in top_words:
                    print(f"  {word}: {count}")

            elif command == "search":
                if not args:
                    print("è¯·æä¾›è¦æœç´¢çš„å•è¯")
                else:
                    result = analyzer.search_word(args)
                    print(f"\n'{result['word']}' å‡ºç° {result['count']} æ¬¡ ({result['percentage']}%)")

            elif command == "report":
                if not analyzer.text:
                    print("è¯·å…ˆåŠ è½½æ–‡æœ¬")
                else:
                    analyzer.print_report()

            else:
                print(f"æœªçŸ¥å‘½ä»¤: {command}")

        except KeyboardInterrupt:
            print("\nå†è§ï¼")
            break
        except Exception as e:
            print(f"é”™è¯¯: {e}")


if __name__ == "__main__":
    main()
```
