# CPU架构深度解析

## 课程概述

本教程深入探讨CPU架构的核心概念，从基础架构模型到现代多核处理器设计，帮助你全面理解CPU的工作原理和性能优化策略。

**学习目标**：
- 理解冯诺依曼与哈佛架构的区别
- 掌握五级流水线的工作机制
- 深入了解CPU缓存层次结构
- 比较主流CPU指令集架构
- 学会CPU性能测试与分析方法

---

## 1. 计算机架构基础模型

### 1.1 冯诺依曼架构

冯诺依曼架构是现代计算机的基础，其核心思想是"存储程序"概念。

```
┌─────────────────────────────────────────────────────────────┐
│              冯诺依曼架构（Von Neumann Architecture）          │
└─────────────────────────────────────────────────────────────┘

    ┌───────────────────────────────────────────────────┐
    │              中央处理器 (CPU)                       │
    │  ┌─────────────────┐    ┌─────────────────┐      │
    │  │  控制单元 (CU)   │    │  算术逻辑单元   │      │
    │  │   - 指令译码     │    │     (ALU)      │      │
    │  │   - 控制信号     │    │   - 算术运算    │      │
    │  │   - 时序控制     │    │   - 逻辑运算    │      │
    │  └─────────────────┘    └─────────────────┘      │
    │            │                      │                │
    │            └──────────┬───────────┘                │
    │                       │                            │
    │                  ┌─────────┐                       │
    │                  │ 寄存器组 │                       │
    │                  └─────────┘                       │
    └───────────────────────┬───────────────────────────┘
                            │
            ┌───────────────┴───────────────┐
            │        系统总线 (Bus)          │
            │   - 数据总线 (Data Bus)        │
            │   - 地址总线 (Address Bus)     │
            │   - 控制总线 (Control Bus)     │
            └───────────────┬───────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
   ┌─────────┐         ┌─────────┐        ┌─────────┐
   │  内存   │         │ 输入设备 │        │ 输出设备 │
   │ (RAM)   │         │ (Input) │        │ (Output)│
   │  指令   │         │ 键盘/鼠标│        │ 显示器   │
   │  数据   │         │  网卡   │        │  打印机  │
   └─────────┘         └─────────┘        └─────────┘
```

**特点**：
- 数据和指令共享同一总线和存储器
- 简化硬件设计
- 存在冯诺依曼瓶颈（总线带宽限制）

### 1.2 哈佛架构

哈佛架构将指令和数据分离存储，提高并行处理能力。

```
┌─────────────────────────────────────────────────────────────┐
│               哈佛架构（Harvard Architecture）                │
└─────────────────────────────────────────────────────────────┘

                    ┌─────────────────────┐
                    │   中央处理器 (CPU)   │
                    │                     │
                    │  ┌────────┐         │
                    │  │  ALU   │         │
                    │  └────────┘         │
                    │       │             │
                    │  ┌────────┐         │
                    │  │寄存器组│         │
                    │  └────────┘         │
                    └──────┬───────┬──────┘
                           │       │
              ┌────────────┘       └────────────┐
              │                                 │
    ┌─────────▼─────────┐           ┌──────────▼──────────┐
    │   指令总线         │           │    数据总线          │
    │ (Instruction Bus) │           │   (Data Bus)        │
    └─────────┬─────────┘           └──────────┬──────────┘
              │                                 │
    ┌─────────▼─────────┐           ┌──────────▼──────────┐
    │   指令存储器       │           │    数据存储器        │
    │(Program Memory)   │           │  (Data Memory)      │
    │  - Flash/ROM      │           │    - RAM/Cache      │
    │  - 只读或少写      │           │    - 频繁读写       │
    └───────────────────┘           └─────────────────────┘
```

**优势**：
- 允许同时取指令和访问数据
- 提高吞吐量
- 常用于DSP和嵌入式系统

### 1.3 改进型哈佛架构

现代CPU采用改进型哈佛架构，结合两者优势。

```
┌─────────────────────────────────────────────────────────────┐
│          现代CPU架构（Modified Harvard Architecture）         │
└─────────────────────────────────────────────────────────────┘

                ┌──────────────────────────┐
                │       CPU Core           │
                │  ┌─────────┐             │
                │  │   ALU   │             │
                │  └─────────┘             │
                │  ┌─────────┐             │
                │  │寄存器文件│             │
                │  └─────────┘             │
                └────┬──────────────┬──────┘
                     │              │
        ┌────────────┘              └────────────┐
        │                                        │
  ┌─────▼──────┐                        ┌───────▼──────┐
  │ L1 I-Cache │                        │ L1 D-Cache   │
  │ (指令缓存)  │                        │ (数据缓存)    │
  │   32-64KB  │                        │   32-64KB    │
  └─────┬──────┘                        └───────┬──────┘
        │                                        │
        └────────────┬──────────────────────────┘
                     │
              ┌──────▼───────┐
              │  L2 Cache    │  统一缓存
              │  256KB-1MB   │  (指令+数据)
              └──────┬───────┘
                     │
              ┌──────▼───────┐
              │  L3 Cache    │  共享缓存
              │   8-64MB     │  (多核共享)
              └──────┬───────┘
                     │
              ┌──────▼───────┐
              │   主内存     │
              │   (RAM)      │
              └──────────────┘
```

---

## 2. CPU流水线技术

### 2.1 五级经典流水线

流水线技术通过并行处理提高指令吞吐量。

```
┌─────────────────────────────────────────────────────────────┐
│              五级流水线（5-Stage Pipeline）                   │
└─────────────────────────────────────────────────────────────┘

阶段1：取指（IF - Instruction Fetch）
  ┌──────────────────────────────────────────┐
  │  从指令缓存读取指令                        │
  │  PC (程序计数器) → 指令地址                │
  │  指令 → IR (指令寄存器)                    │
  └──────────────┬───────────────────────────┘
                 │
阶段2：译码（ID - Instruction Decode）
  ┌──────────────▼───────────────────────────┐
  │  解析指令操作码和操作数                    │
  │  读取寄存器值                              │
  │  生成控制信号                              │
  └──────────────┬───────────────────────────┘
                 │
阶段3：执行（EX - Execute）
  ┌──────────────▼───────────────────────────┐
  │  ALU执行算术/逻辑运算                      │
  │  计算内存地址（Load/Store指令）            │
  │  计算分支目标地址                          │
  └──────────────┬───────────────────────────┘
                 │
阶段4：访存（MEM - Memory Access）
  ┌──────────────▼───────────────────────────┐
  │  访问数据缓存/内存                         │
  │  Load：从内存读取数据                      │
  │  Store：将数据写入内存                     │
  └──────────────┬───────────────────────────┘
                 │
阶段5：写回（WB - Write Back）
  ┌──────────────▼───────────────────────────┐
  │  将结果写回寄存器                          │
  │  更新处理器状态                            │
  └──────────────────────────────────────────┘

时间流水线示意：
Clock:  1    2    3    4    5    6    7    8    9
指令1:  IF   ID   EX   MEM  WB
指令2:       IF   ID   EX   MEM  WB
指令3:            IF   ID   EX   MEM  WB
指令4:                 IF   ID   EX   MEM  WB
指令5:                      IF   ID   EX   MEM  WB

理想情况：吞吐量 = 1条指令/时钟周期
```

### 2.2 流水线冒险（Hazards）

```
┌─────────────────────────────────────────────────────────────┐
│                  流水线冒险类型与解决方案                      │
└─────────────────────────────────────────────────────────────┘

1. 结构冒险（Structural Hazard）
   ┌─────────────────────────────────────┐
   │  问题：硬件资源冲突                  │
   │  示例：指令和数据同时访问内存         │
   └─────────────────────────────────────┘
   解决方案：
   - 哈佛架构（分离指令/数据缓存）
   - 增加硬件资源（多端口寄存器文件）

2. 数据冒险（Data Hazard）
   ┌─────────────────────────────────────┐
   │  问题：指令间存在数据依赖             │
   │  示例：                              │
   │    ADD R1, R2, R3  # R1 = R2 + R3   │
   │    SUB R4, R1, R5  # 需要等R1写回    │
   └─────────────────────────────────────┘

   RAW（Read After Write）示例：
   Clock:    1    2    3    4    5    6
   ADD:      IF   ID   EX   MEM  WB
   SUB:           IF   ID   停顿  EX   MEM
                      └─等待R1写回

   解决方案：
   a) 数据前递（Forwarding/Bypassing）
      ┌────────────────────────────┐
      │  EX/MEM → EX (旁路)         │
      │  MEM/WB → EX (旁路)         │
      └────────────────────────────┘

   b) 流水线停顿（Pipeline Stall）
      插入NOP（空操作）气泡

3. 控制冒险（Control Hazard）
   ┌─────────────────────────────────────┐
   │  问题：分支指令导致指令流不确定      │
   │  示例：                              │
   │    BEQ R1, R2, LABEL  # 条件跳转    │
   │    ADD R3, R4, R5     # 可能不执行   │
   └─────────────────────────────────────┘

   解决方案：
   a) 分支预测（Branch Prediction）
      - 静态预测：总是预测跳转/不跳转
      - 动态预测：基于历史记录（2位计数器）

      2位饱和计数器状态机：
      ┌─────────────────────────────┐
      │  11 ←→ 10     01 ←→ 00     │
      │(强跳)(弱跳) (弱不跳)(强不跳) │
      └─────────────────────────────┘

   b) 延迟槽（Delay Slot）
      在分支指令后总是执行1条指令

   c) 推测执行（Speculative Execution）
      预测执行后续指令，错误则回滚
```

### 2.3 超标量架构

现代CPU通过超标量技术实现指令级并行。

```
┌─────────────────────────────────────────────────────────────┐
│           超标量处理器（Superscalar Processor）               │
└─────────────────────────────────────────────────────────────┘

                    ┌─────────────┐
                    │  指令缓存    │
                    └──────┬──────┘
                           │
                    ┌──────▼──────┐
                    │  取指单元    │  每周期取4-6条指令
                    │(Fetch Unit) │
                    └──────┬──────┘
                           │
                    ┌──────▼──────┐
                    │  指令队列    │
                    └──────┬──────┘
                           │
                    ┌──────▼──────┐
                    │  译码单元    │  并行译码多条指令
                    │(Decode Unit)│
                    └──────┬──────┘
                           │
                    ┌──────▼──────┐
                    │  重命名单元  │  消除WAW/WAR冒险
                    │  (Rename)   │  (寄存器重命名)
                    └──────┬──────┘
                           │
                    ┌──────▼──────┐
                    │  发射队列    │  乱序发射
                    │ (Issue Queue)│
                    └──────┬──────┘
                           │
          ┌────────────────┼────────────────┐
          │                │                │
    ┌─────▼─────┐   ┌──────▼──────┐  ┌─────▼─────┐
    │  整数ALU  │   │ 浮点运算单元 │  │ Load/Store│
    │  (2-4个)  │   │    (FPU)    │  │   单元    │
    │           │   │  (1-2个)    │  │  (2个)    │
    └─────┬─────┘   └──────┬──────┘  └─────┬─────┘
          │                │                │
          └────────────────┼────────────────┘
                           │
                    ┌──────▼──────┐
                    │  重排序缓冲  │  保证顺序提交
                    │    (ROB)    │
                    └──────┬──────┘
                           │
                    ┌──────▼──────┐
                    │  提交阶段    │
                    │  (Commit)   │
                    └─────────────┘

示例：同时执行多条指令
Clock 1:  [ADD] [MUL] [LOAD] [SUB]  ← 4条指令并行执行
          └整数  └浮点  └访存   └整数
```

---

## 3. CPU缓存架构

### 3.1 缓存层次结构

```
┌─────────────────────────────────────────────────────────────┐
│              缓存层次金字塔（Cache Hierarchy）                │
└─────────────────────────────────────────────────────────────┘

速度     容量        延迟           位置
快       小         低             ↑
│                                  │
│   ┌────────────────────┐         │
│   │   CPU寄存器         │  ~1KB   0.3ns
│   │  (Registers)       │         │
│   └────────────────────┘         │
│          ↓                       │
│   ┌────────────────────┐         │
│   │   L1 Cache         │  32-64KB  ~1ns (4 cycles)
│   │  - L1i (指令)       │         │
│   │  - L1d (数据)       │         │
│   └────────────────────┘         │
│          ↓                       │
│   ┌────────────────────┐         │
│   │   L2 Cache         │  256KB-1MB  ~4ns (12 cycles)
│   │  (统一缓存)         │         │
│   └────────────────────┘         │
│          ↓                       │
│   ┌────────────────────┐         │
│   │   L3 Cache         │  8-64MB   ~15ns (40 cycles)
│   │  (多核共享)         │         │
│   └────────────────────┘         │
│          ↓                       │
│   ┌────────────────────┐         │
│   │   主内存(RAM)       │  8-128GB  ~80ns (200 cycles)
│   │    (DDR4/DDR5)     │         │
│   └────────────────────┘         │
│          ↓                       │
│   ┌────────────────────┐         │
│   │   SSD存储          │  256GB-4TB  ~100μs
│   └────────────────────┘         │
│          ↓                       │
│   ┌────────────────────┐         │
│   │   HDD存储          │  1-10TB    ~10ms
│   └────────────────────┘         │
↓                                  ↓
慢       大         高
```

### 3.2 缓存组织结构

```
┌─────────────────────────────────────────────────────────────┐
│              直接映射缓存（Direct-Mapped Cache）              │
└─────────────────────────────────────────────────────────────┘

内存地址(32位)分解：
┌────────────┬────────────┬────────────┐
│   Tag      │   Index    │   Offset   │
│  (20 bits) │  (8 bits)  │  (4 bits)  │
└────────────┴────────────┴────────────┘
     │            │             │
     │            │             └─ 块内偏移(16字节块)
     │            └─ 缓存行索引(256行)
     └─ 标签(用于匹配)

缓存结构：
Index  Valid  Tag        Data (16 bytes)
┌────┬─────┬──────────┬─────────────────────────┐
│ 0  │  1  │ 0x1234   │ [数据块0]                │
├────┼─────┼──────────┼─────────────────────────┤
│ 1  │  1  │ 0xABCD   │ [数据块1]                │
├────┼─────┼──────────┼─────────────────────────┤
│ .. │  .. │   ...    │  ...                    │
├────┼─────┼──────────┼─────────────────────────┤
│255 │  0  │ 0x0000   │ [无效]                   │
└────┴─────┴──────────┴─────────────────────────┘

查找流程：
1. 提取Index → 找到缓存行
2. 检查Valid位 → 是否有效
3. 比较Tag → 是否匹配
4. 提取Offset → 获取数据

┌─────────────────────────────────────────────────────────────┐
│           组相联缓存（Set-Associative Cache）                │
└─────────────────────────────────────────────────────────────┘

4路组相联示例（每组4个缓存行）：

Set    Way 0        Way 1        Way 2        Way 3
     V Tag Data   V Tag Data   V Tag Data   V Tag Data
┌──┬──┬───┬────┬──┬───┬────┬──┬───┬────┬──┬───┬────┐
│0 │1 │0xA│... │1 │0xB│... │1 │0xC│... │0 │   │    │
├──┼──┼───┼────┼──┼───┼────┼──┼───┼────┼──┼───┼────┤
│1 │1 │0xD│... │1 │0xE│... │0 │   │    │1 │0xF│... │
├──┼──┼───┼────┼──┼───┼────┼──┼───┼────┼──┼───┼────┤
│..│  │   │    │  │   │    │  │   │    │  │   │    │
└──┴──┴───┴────┴──┴───┴────┴──┴───┴────┴──┴───┴────┘

优点：降低冲突失效率
缺点：查找复杂度增加（需并行比较4个Tag）

替换策略：
- LRU (Least Recently Used)：替换最久未使用
- FIFO (First In First Out)：替换最早进入
- Random：随机替换
```

### 3.3 缓存一致性协议（MESI）

多核系统中需要保证缓存一致性。

```
┌─────────────────────────────────────────────────────────────┐
│              MESI协议状态机（Cache Coherence）               │
└─────────────────────────────────────────────────────────────┘

状态定义：
M (Modified)   - 已修改：缓存行有效，数据已修改，与内存不一致
E (Exclusive)  - 独占：缓存行有效，数据未修改，只有一个核持有
S (Shared)     - 共享：缓存行有效，多个核持有相同数据
I (Invalid)    - 无效：缓存行无效

状态转换图：
              读取未命中
    ┌────────其他核无此数据─────────┐
    │                             │
    │      ┌───────────┐          ▼
    │   ┌─→│     E     │←──写入自己拥有
    │   │  │  (独占)   │     的数据
    │   │  └─────┬─────┘
    │   │        │写入
    │   │        ▼
    │   │  ┌───────────┐
    │   │  │     M     │
    │   │  │  (已修改)  │
    │   │  └─────┬─────┘
    │   │        │其他核读取
    │   │        │(写回内存)
    │   │        ▼
    │   │  ┌───────────┐   读取未命中
    └───┼─→│     S     │←─其他核也有─┘
        │  │  (共享)   │
        │  └─────┬─────┘
        │        │写入/失效
        │        ▼
        │  ┌───────────┐
        └──│     I     │
           │  (无效)   │
           └───────────┘

实际案例：
Core 0          Core 1          内存
L1: [I]         L1: [I]        Addr X = 10
  │               │                 │
  ├─ Read X ──────┼─────────────────┤
  │               │                 │
L1: [E] X=10    L1: [I]        Addr X = 10
  │               │                 │
  │               ├─ Read X ────────┤
  │               │                 │
L1: [S] X=10    L1: [S] X=10   Addr X = 10
  │               │                 │
  ├─ Write X=20───┼─ Invalidate────┤
  │               │                 │
L1: [M] X=20    L1: [I]        Addr X = 10(旧值)
  │               │                 │
  │               ├─ Read X ────────┤
  │               │   (Core 0写回)  │
  ├─ Flush ───────┼─────────────────┤
  │               │                 │
L1: [S] X=20    L1: [S] X=20   Addr X = 20(新值)
```

---

## 4. 多核与NUMA架构

### 4.1 多核处理器架构

```
┌─────────────────────────────────────────────────────────────┐
│            现代多核处理器（Multi-Core Processor）             │
└─────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────┐
│                    CPU Package                             │
│                                                            │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐    │
│  │   Core 0     │  │   Core 1     │  │   Core 2     │    │
│  │  ┌────────┐  │  │  ┌────────┐  │  │  ┌────────┐  │    │
│  │  │  ALU   │  │  │  │  ALU   │  │  │  │  ALU   │  │    │
│  │  └────────┘  │  │  └────────┘  │  │  └────────┘  │    │
│  │  ┌────────┐  │  │  ┌────────┐  │  │  ┌────────┐  │    │
│  │  │L1i 32KB│  │  │  │L1i 32KB│  │  │  │L1i 32KB│  │    │
│  │  ├────────┤  │  │  ├────────┤  │  │  ├────────┤  │    │
│  │  │L1d 32KB│  │  │  │L1d 32KB│  │  │  │L1d 32KB│  │    │
│  │  └────────┘  │  │  └────────┘  │  │  └────────┘  │    │
│  │  ┌────────┐  │  │  ┌────────┐  │  │  ┌────────┐  │    │
│  │  │L2 256KB│  │  │  │L2 256KB│  │  │  │L2 256KB│  │    │
│  │  └────┬───┘  │  │  └────┬───┘  │  │  └────┬───┘  │    │
│  └───────┼──────┘  └───────┼──────┘  └───────┼──────┘    │
│          │                 │                 │            │
│          └─────────────────┼─────────────────┘            │
│                            │                              │
│                   ┌────────▼────────┐                     │
│                   │  L3 Cache(共享) │                     │
│                   │     16-32MB     │                     │
│                   └────────┬────────┘                     │
│                            │                              │
│                   ┌────────▼────────┐                     │
│                   │  内存控制器     │                     │
│                   │(Memory Ctrl)   │                     │
│                   └────────┬────────┘                     │
└────────────────────────────┼──────────────────────────────┘
                             │
                    ┌────────▼────────┐
                    │   DDR4/DDR5     │
                    │     内存        │
                    └─────────────────┘
```

### 4.2 NUMA架构

非统一内存访问（NUMA）架构用于多路服务器。

```
┌─────────────────────────────────────────────────────────────┐
│          NUMA架构（Non-Uniform Memory Access）               │
└─────────────────────────────────────────────────────────────┘

双路服务器示例（2个NUMA节点）：

┌─────────────────────────┐      ┌─────────────────────────┐
│      NUMA Node 0        │      │      NUMA Node 1        │
│                         │      │                         │
│  ┌─────────────────┐    │      │    ┌─────────────────┐  │
│  │  CPU 0 (8核)    │    │      │    │  CPU 1 (8核)    │  │
│  │  ┌───┐ ┌───┐   │    │      │    │   ┌───┐ ┌───┐  │  │
│  │  │C0 │ │C1 │   │    │      │    │   │C8 │ │C9 │  │  │
│  │  └───┘ └───┘   │    │      │    │   └───┘ └───┘  │  │
│  │  ...  ...  ... │    │      │    │   ...  ...  ..  │  │
│  │  L3 Cache(共享) │    │      │    │  L3 Cache(共享)  │  │
│  └────────┬────────┘    │      │    └────────┬────────┘  │
│           │             │      │             │           │
│  ┌────────▼────────┐    │      │    ┌────────▼────────┐  │
│  │  内存控制器      │    │      │    │  内存控制器      │  │
│  └────────┬────────┘    │      │    └────────┬────────┘  │
│           │             │      │             │           │
│  ┌────────▼────────┐    │      │    ┌────────▼────────┐  │
│  │  本地内存(64GB)  │    │      │    │  本地内存(64GB)  │  │
│  │    (Local)      │    │      │    │    (Local)      │  │
│  └─────────────────┘    │      │    └─────────────────┘  │
│           │             │      │             │           │
└───────────┼─────────────┘      └─────────────┼───────────┘
            │                                  │
            └────────────┐    ┌────────────────┘
                         │    │
                    ┌────▼────▼────┐
                    │  QPI/UPI总线 │  互连总线
                    │ (Inter-Connect)│
                    └──────────────┘

内存访问延迟：
- 本地内存访问(Local)：~80ns
- 远程内存访问(Remote)：~130ns (1.6倍延迟)

NUMA亲和性优化：
┌──────────────────────────────────────┐
│  线程调度策略                         │
│  - 尽量将进程绑定到同一NUMA节点       │
│  - 内存分配优先使用本地节点           │
│  - 避免跨节点内存访问                 │
└──────────────────────────────────────┘
```

---

## 5. 指令集架构对比

### 5.1 x86 vs ARM vs RISC-V

```
┌─────────────────────────────────────────────────────────────┐
│              主流指令集架构对比                               │
└─────────────────────────────────────────────────────────────┘

特性对比表：
┌──────────┬──────────────┬──────────────┬──────────────┐
│ 特性     │    x86-64    │   ARM v8/v9  │   RISC-V     │
├──────────┼──────────────┼──────────────┼──────────────┤
│ 设计理念 │ CISC复杂指令 │ RISC精简指令 │ RISC精简指令 │
│ 指令长度 │ 变长(1-15B)  │ 定长(32位)   │ 定长(32位)   │
│ 寄存器数 │ 16个通用     │ 31个通用     │ 32个通用     │
│ 指令数量 │ 3000+        │ ~500         │ ~200(基础)   │
│ 功耗     │ 高(15-125W)  │ 低(1-15W)    │ 极低(可调)   │
│ 性能     │ 高           │ 中-高        │ 中           │
│ 授权模式 │ Intel专有    │ ARM授权收费  │ 开源免费     │
│ 主要应用 │ PC/服务器    │ 移动/嵌入式  │ 嵌入式/IoT   │
└──────────┴──────────────┴──────────────┴──────────────┘

指令示例对比（数组求和）：

x86-64汇编（CISC风格）：
    mov  ecx, 0          ; 初始化计数器
    mov  eax, 0          ; 初始化和
loop_start:
    add  eax, [rdi+rcx*4] ; 直接内存寻址+累加
    inc  ecx
    cmp  ecx, 100
    jl   loop_start       ; 条件跳转

ARM汇编（RISC风格）：
    mov  x2, #0          ; 初始化计数器
    mov  x3, #0          ; 初始化和
loop_start:
    ldr  w4, [x0, x2, lsl #2]  ; 加载内存
    add  x3, x3, x4      ; 累加
    add  x2, x2, #1      ; 计数器+1
    cmp  x2, #100
    b.lt loop_start      ; 条件跳转

RISC-V汇编（纯RISC风格）：
    li   t0, 0           ; 初始化计数器
    li   t1, 0           ; 初始化和
loop_start:
    slli t2, t0, 2       ; t2 = t0 * 4
    add  t2, a0, t2      ; 计算地址
    lw   t3, 0(t2)       ; 加载内存
    add  t1, t1, t3      ; 累加
    addi t0, t0, 1       ; 计数器+1
    li   t4, 100
    blt  t0, t4, loop_start  ; 条件跳转
```

### 5.2 SIMD向量扩展

```
┌─────────────────────────────────────────────────────────────┐
│              SIMD向量指令（Single Instruction Multiple Data)│
└─────────────────────────────────────────────────────────────┘

x86 SIMD演进：
MMX (1997)    → 64位, 8个寄存器
SSE (1999)    → 128位, 16个寄存器
AVX (2011)    → 256位, 16个寄存器
AVX-512(2016) → 512位, 32个寄存器

AVX-512向量加法示例：
┌────────────────────────────────────────────────────────┐
│  寄存器ZMM0: [a0][a1][a2][a3]...[a15] (16个float)     │
│  寄存器ZMM1: [b0][b1][b2][b3]...[b15] (16个float)     │
│              ─────────────────────────                 │
│  VADDPS ZMM2, ZMM0, ZMM1  (单指令16次加法)            │
│              ─────────────────────────                 │
│  寄存器ZMM2: [a0+b0][a1+b1]...[a15+b15]               │
└────────────────────────────────────────────────────────┘

向量 vs 标量性能对比：
标量代码（每次1个元素）：
    for (int i = 0; i < 16; i++)
        c[i] = a[i] + b[i];
    执行时间：16个周期

向量代码（每次16个元素）：
    __m512 va = _mm512_load_ps(a);
    __m512 vb = _mm512_load_ps(b);
    __m512 vc = _mm512_add_ps(va, vb);
    _mm512_store_ps(c, vc);
    执行时间：1个周期（理想情况）

加速比：16倍
```

---

## 6. CPU性能测试实战

### 6.1 CPU信息查询

```bash
#!/bin/bash
# CPU架构信息查询脚本

echo "========== CPU基本信息 =========="
# Linux系统
lscpu | grep -E "Architecture|CPU\(s\)|Model name|Thread|Core|Socket|Cache"

# 或使用/proc/cpuinfo
cat /proc/cpuinfo | grep -E "processor|model name|cpu MHz|cache size" | head -20

echo -e "\n========== CPU缓存信息 =========="
# 详细缓存层次结构
lscpu -C

# 或查看sysfs
for i in /sys/devices/system/cpu/cpu0/cache/index*; do
    echo "$(basename $i):"
    cat $i/level $i/type $i/size $i/coherency_line_size 2>/dev/null
done

echo -e "\n========== NUMA拓扑 =========="
numactl --hardware

echo -e "\n========== CPU频率信息 =========="
# 查看当前频率
cat /proc/cpuinfo | grep "cpu MHz"

# 查看频率范围
cpupower frequency-info

echo -e "\n========== CPU特性标志 =========="
# 查看支持的指令集
cat /proc/cpuinfo | grep flags | head -1 | grep -oE "sse|avx|avx2|avx512"
```

### 6.2 性能基准测试

```python
#!/usr/bin/env python3
"""
CPU性能基准测试脚本
测试项：整数运算、浮点运算、内存带宽、缓存延迟
"""

import time
import numpy as np
import subprocess
import platform

def test_integer_performance():
    """测试整数运算性能（GOPS）"""
    print("=== 整数运算测试 ===")
    iterations = 100_000_000

    start = time.perf_counter()
    result = 0
    for i in range(iterations):
        result += i * 2 + 1
    end = time.perf_counter()

    elapsed = end - start
    gops = (iterations * 2) / elapsed / 1e9  # 每次循环2个操作
    print(f"整数运算性能: {gops:.2f} GOPS")
    print(f"执行时间: {elapsed:.3f} 秒")
    return gops

def test_floating_point():
    """测试浮点运算性能（GFLOPS）"""
    print("\n=== 浮点运算测试 ===")
    size = 10000
    iterations = 1000

    a = np.random.rand(size).astype(np.float64)
    b = np.random.rand(size).astype(np.float64)

    start = time.perf_counter()
    for _ in range(iterations):
        c = a * b + a  # 每元素2个浮点操作
    end = time.perf_counter()

    elapsed = end - start
    gflops = (size * 2 * iterations) / elapsed / 1e9
    print(f"浮点运算性能: {gflops:.2f} GFLOPS")
    print(f"执行时间: {elapsed:.3f} 秒")
    return gflops

def test_memory_bandwidth():
    """测试内存带宽（GB/s）"""
    print("\n=== 内存带宽测试 ===")
    size = 100_000_000  # 100M个float64 = 800MB
    iterations = 10

    data = np.random.rand(size).astype(np.float64)

    # 读取测试
    start = time.perf_counter()
    for _ in range(iterations):
        checksum = np.sum(data)
    end = time.perf_counter()

    bytes_transferred = size * 8 * iterations  # float64 = 8字节
    bandwidth = bytes_transferred / (end - start) / 1e9
    print(f"内存读取带宽: {bandwidth:.2f} GB/s")

    # 写入测试
    start = time.perf_counter()
    for _ in range(iterations):
        data[:] = 1.0
    end = time.perf_counter()

    bandwidth = bytes_transferred / (end - start) / 1e9
    print(f"内存写入带宽: {bandwidth:.2f} GB/s")
    return bandwidth

def test_cache_latency():
    """测试缓存延迟"""
    print("\n=== 缓存延迟测试 ===")

    # 测试不同大小数组的访问延迟
    sizes = [
        (8 * 1024, "L1 Cache (8KB)"),
        (128 * 1024, "L2 Cache (128KB)"),
        (8 * 1024 * 1024, "L3 Cache (8MB)"),
        (128 * 1024 * 1024, "Main Memory (128MB)")
    ]

    iterations = 10_000_000

    for size_bytes, label in sizes:
        size = size_bytes // 8  # float64数组长度
        data = np.random.rand(size).astype(np.float64)

        # 随机访问模式
        indices = np.random.randint(0, size, iterations)

        start = time.perf_counter()
        total = 0
        for idx in indices:
            total += data[idx]
        end = time.perf_counter()

        latency_ns = (end - start) / iterations * 1e9
        print(f"{label}: {latency_ns:.1f} ns/access")

def test_simd_performance():
    """测试SIMD向量化性能"""
    print("\n=== SIMD向量化测试 ===")
    size = 10_000_000
    iterations = 100

    a = np.random.rand(size).astype(np.float32)
    b = np.random.rand(size).astype(np.float32)

    # 向量化操作（自动使用SIMD）
    start = time.perf_counter()
    for _ in range(iterations):
        c = a * b + a
    end = time.perf_counter()

    elapsed = end - start
    gflops = (size * 2 * iterations) / elapsed / 1e9
    print(f"向量化浮点性能: {gflops:.2f} GFLOPS")
    print(f"执行时间: {elapsed:.3f} 秒")

def get_cpu_info():
    """获取CPU信息"""
    print("=== CPU信息 ===")
    print(f"处理器: {platform.processor()}")
    print(f"架构: {platform.machine()}")

    try:
        if platform.system() == "Linux":
            # 获取CPU型号
            with open("/proc/cpuinfo") as f:
                for line in f:
                    if "model name" in line:
                        print(f"型号: {line.split(':')[1].strip()}")
                        break

            # 获取缓存信息
            result = subprocess.run(['lscpu'], capture_output=True, text=True)
            for line in result.stdout.split('\n'):
                if 'L1d cache' in line or 'L2 cache' in line or 'L3 cache' in line:
                    print(line)
    except:
        pass
    print()

def main():
    """主函数"""
    print("CPU性能基准测试")
    print("=" * 50)

    get_cpu_info()

    int_perf = test_integer_performance()
    float_perf = test_floating_point()
    mem_bw = test_memory_bandwidth()
    test_cache_latency()
    test_simd_performance()

    print("\n" + "=" * 50)
    print("测试总结:")
    print(f"整数性能: {int_perf:.2f} GOPS")
    print(f"浮点性能: {float_perf:.2f} GFLOPS")
    print(f"内存带宽: {mem_bw:.2f} GB/s")
    print("=" * 50)

if __name__ == "__main__":
    main()
```

### 6.3 使用标准工具测试

```bash
#!/bin/bash
# 使用标准工具进行CPU性能测试

echo "========== sysbench CPU测试 =========="
# 安装：apt install sysbench
sysbench cpu --cpu-max-prime=20000 --threads=4 run

echo -e "\n========== stress-ng多项测试 =========="
# 安装：apt install stress-ng
# CPU整数运算
stress-ng --cpu 4 --cpu-method int64 --metrics --timeout 10s

# CPU浮点运算
stress-ng --cpu 4 --cpu-method double --metrics --timeout 10s

echo -e "\n========== 7-zip基准测试 =========="
# 安装：apt install p7zip-full
7z b -mmt4

echo -e "\n========== OpenSSL性能测试 =========="
# 测试AES加密性能（CPU密集）
openssl speed -multi 4 aes-256-cbc

echo -e "\n========== 内存带宽测试（mbw）=========="
# 安装：apt install mbw
mbw -n 5 1000

echo -e "\n========== cachebench缓存测试 =========="
# 需要编译安装cachebench
# 测试L1/L2/L3缓存和主内存延迟
```

---

## 7. 实战案例：性能调优

### 7.1 缓存优化示例

```python
#!/usr/bin/env python3
"""
缓存友好 vs 缓存不友好代码对比
"""

import numpy as np
import time

def matrix_multiply_row_major(A, B):
    """按行访问（缓存友好）"""
    n = A.shape[0]
    C = np.zeros((n, n))

    for i in range(n):
        for j in range(n):
            for k in range(n):
                C[i][j] += A[i][k] * B[k][j]
    return C

def matrix_multiply_col_major(A, B):
    """按列访问（缓存不友好）"""
    n = A.shape[0]
    C = np.zeros((n, n))

    # 外层循环变为列
    for j in range(n):
        for i in range(n):
            for k in range(n):
                C[i][j] += A[i][k] * B[k][j]
    return C

def matrix_multiply_blocked(A, B, block_size=64):
    """分块矩阵乘法（缓存优化）"""
    n = A.shape[0]
    C = np.zeros((n, n))

    for i0 in range(0, n, block_size):
        for j0 in range(0, n, block_size):
            for k0 in range(0, n, block_size):
                # 处理一个块
                for i in range(i0, min(i0 + block_size, n)):
                    for j in range(j0, min(j0 + block_size, n)):
                        for k in range(k0, min(k0 + block_size, n)):
                            C[i][j] += A[i][k] * B[k][j]
    return C

# 性能对比
size = 512
A = np.random.rand(size, size)
B = np.random.rand(size, size)

print("矩阵乘法缓存优化对比 ({}x{})".format(size, size))

# 按行访问
start = time.time()
C1 = matrix_multiply_row_major(A, B)
t1 = time.time() - start
print(f"行优先访问: {t1:.3f} 秒")

# 按列访问
start = time.time()
C2 = matrix_multiply_col_major(A, B)
t2 = time.time() - start
print(f"列优先访问: {t2:.3f} 秒 (慢 {t2/t1:.1f}x)")

# 分块优化
start = time.time()
C3 = matrix_multiply_blocked(A, B)
t3 = time.time() - start
print(f"分块优化: {t3:.3f} 秒 (快 {t1/t3:.1f}x)")

# NumPy内置（高度优化）
start = time.time()
C4 = np.dot(A, B)
t4 = time.time() - start
print(f"NumPy优化: {t4:.3f} 秒 (快 {t1/t4:.1f}x)")
```

### 7.2 NUMA亲和性优化

```bash
#!/bin/bash
# NUMA亲和性优化示例

echo "========== 查看NUMA配置 =========="
numactl --hardware

echo -e "\n========== 测试NUMA影响 =========="

# 默认运行（可能跨节点）
echo "默认运行:"
time numactl --cpunodebind=0 --membind=1 stress-ng --vm 1 --vm-bytes 1G --timeout 5s

# NUMA优化（CPU和内存在同一节点）
echo -e "\nNUMA优化:"
time numactl --cpunodebind=0 --membind=0 stress-ng --vm 1 --vm-bytes 1G --timeout 5s

echo -e "\n========== 绑定进程到特定核心 =========="
# 使用taskset绑定到CPU 0-3
taskset -c 0-3 your_application

# 或使用numactl
numactl --physcpubind=0-3 --membind=0 your_application
```

---

## 8. 学习资源与总结

### 8.1 推荐资源

1. **经典书籍**：
   - 《计算机体系结构：量化研究方法》(Hennessy & Patterson)
   - 《深入理解计算机系统》(CSAPP)
   - 《现代处理器设计：超标量处理器基础》

2. **在线资源**：
   - Intel开发者手册（x86架构权威文档）
   - ARM架构参考手册
   - RISC-V指令集手册

3. **性能分析工具**：
   - perf（Linux性能分析）
   - Intel VTune Profiler
   - AMD uProf

### 8.2 关键要点总结

```
┌─────────────────────────────────────────────────────────────┐
│                    CPU架构核心概念                            │
└─────────────────────────────────────────────────────────────┘

1. 架构模型
   ├─ 冯诺依曼：指令数据共享总线
   ├─ 哈佛：指令数据分离
   └─ 现代：多级缓存 + 改进哈佛

2. 流水线技术
   ├─ 五级流水：IF → ID → EX → MEM → WB
   ├─ 超标量：多发射 + 乱序执行
   └─ 冒险处理：数据前递 + 分支预测

3. 缓存层次
   ├─ L1：32-64KB，~1ns
   ├─ L2：256KB-1MB，~4ns
   ├─ L3：8-64MB，~15ns
   └─ 一致性：MESI协议

4. 多核架构
   ├─ SMP：对称多处理
   ├─ NUMA：非统一内存访问
   └─ 亲和性：绑定CPU和内存节点

5. 指令集
   ├─ x86：CISC，高性能
   ├─ ARM：RISC，低功耗
   └─ RISC-V：开源，灵活

6. 性能优化
   ├─ 缓存友好：顺序访问 + 分块
   ├─ SIMD：向量化计算
   └─ NUMA：本地化访问
└─────────────────────────────────────────────────────────────┘
```

### 8.3 实践练习

1. 使用`lscpu`和`numactl`分析你的系统架构
2. 编写程序测试L1/L2/L3缓存大小和延迟
3. 对比标量和SIMD代码的性能差异
4. 使用`perf`分析缓存命中率
5. 实现并优化矩阵乘法，观察性能提升

---

**下一步**：学习内存系统架构，深入理解DRAM工作原理和DDR技术演进。

**文件大小**：约30KB
**最后更新**：2024年
